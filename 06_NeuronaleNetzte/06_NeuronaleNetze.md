# 6. Neuronale Netze

Neuronale Netze sind ein zentraler Bestandteil moderner KI-Systeme. Sie sind inspiriert vom menschlichen Gehirn, bestehen jedoch aus **kÃ¼nstlichen Neuronen**, die Informationen verarbeiten, weiterleiten und lernen, Muster in Daten zu erkennen.

---

## 6.1 Grundidee kÃ¼nstlicher Neuronen

Ein kÃ¼nstliches Neuron erhÃ¤lt mehrere Eingangswerte, multipliziert sie mit Gewichtungen, summiert die Ergebnisse auf und entscheidet Ã¼ber eine **Aktivierungsfunktion**, ob und wie stark es â€anspringtâ€œ.

### Aufbau eines kÃ¼nstlichen Neurons (Perzeptron):

Das Perzeptron ist das Ã¤lteste und zugleich einfachste Modell eines kÃ¼nstlichen Neurons. Es wurde Ende der 1950er Jahre von Frank Rosenblatt entwickelt und kann lineare Entscheidungsgrenzen erlernen. Ein Perzeptron besteht aus:

- **Eingaben:** \( x_1, x_2, ..., x_n \)  
- **Gewichte:** \( w_1, w_2, ..., w_n \)  
- **Berechnung:**  
 z =   âˆ‘ wi xi + b (mit Bias b) wobei \( b \) der **Bias** ist

- **Aktivierung:** Einer Aktivierungsfunktion (z.B. ein Schwellenwert), die entscheidet, ob das Neuron â€feuertâ€œ


Das Perzeptron lernt durch Anpassung der Gewichte, ob ein Datenpunkt zur Klasse 1 oder 0 gehÃ¶rt. Es kann jedoch nur linear separierbare Probleme lÃ¶sen.



## Netzstruktur: Von der Eingabe zur Vorhersage

Ein einzelnes Neuron ist nicht ausreichend fÃ¼r komplexe Aufgaben. Erst durch das **VerknÃ¼pfen mehrerer Neuronen zu Netzwerken** entstehen leistungsfÃ¤hige Strukturen:

### Typische Architektur eines neuronalen Netzes:

- **Eingabeschicht:** Nimmt Rohdaten auf (z.â€¯B. Pixel, Sensordaten)
- **Versteckte Schichten (Hidden Layers):** Transformieren und abstrahieren Merkmale
- **Ausgabeschicht:** Gibt die finale Vorhersage aus (z.â€¯B. Kategorie, Wert)

Netze mit mehreren versteckten Schichten werden als **Mehrschicht-Perzeptrons (MLP)** bezeichnet. Sie gehÃ¶ren zur Klasse der **Feedforward-Netze**, bei denen Informationen nur in eine Richtung flieÃŸen â€“ von der Eingabe zur Ausgabe.

![image](https://github.com/user-attachments/assets/8d540b6c-2be0-49f7-bbd7-b2d951789290)

*Abbildung 11: Feedforward-Netz mit 2 Hidden Layers â€“ Quelle: ORDIX Blog, 2021*


**ErklÃ¤rung:**  

Die Eingabeschicht (blau) nimmt die Merkmale x1 bis x5 auf. Diese werden durch zehn Neuronen in der ersten verdeckten Schicht verarbeitet, anschlieÃŸend durch fÃ¼nf weitere Neuronen in der zweiten versteckten Schicht weitergegeben und schlieÃŸlich zu einer Vorhersage y1 in der Ausgabeschicht (grÃ¼n) zusammengefÃ¼hrt. Jede Verbindung ist mit einem Gewicht versehen, das beim Lernen angepasst wird.




## Anwendung: Bilderkennung

Ein neuronales Netz kann z.â€¯B. lernen, **handgeschriebene Ziffern (0â€“9)** zu erkennen:

1. **Eingabeschicht:** nimmt Pixelwerte des Bildes auf  
2. **Versteckte Schichten:** extrahieren Muster wie Kanten oder Kurven  
3. **Ausgabeschicht:** entscheidet sich fÃ¼r die wahrscheinlichste Ziffer



> Ein neuronales Netz lernt durch viele Beispiele, relevante Merkmale in den Daten zu erkennen â€“ ganz ohne explizit programmierte Regeln.

---

## 6.2 Lernen mit Backpropagation

Damit ein neuronales Netz nicht nur zufÃ¤llige Ausgaben produziert, sondern gezielt Muster erkennen kann, muss es aus Beispielen lernen. Das zentrale Trainingsverfahren fÃ¼r Feedforward-Netze ist der **Backpropagation-Algorithmus** â€“ auf Deutsch: RÃ¼ckwÃ¤rtsausbreitung des Fehlers.

### Ziel: Fehler minimieren

Der Lernprozess basiert auf dem Vergleich zwischen der tatsÃ¤chlichen Ausgabe \( \hat{y} \) des Netzes und dem Zielwert \( y \). Die Differenz wird durch eine **Fehlerfunktion (Loss Function)** quantifiziert, z.â€¯B.:

![image](https://github.com/user-attachments/assets/71d425bc-95e2-435b-ad2a-7f666f5ab9ad)


Ziel ist es, die Summe der Fehler Ã¼ber alle Trainingsbeispiele hinweg zu minimieren. Dazu passt das Netz seine **Gewichte** iterativ an.



### Idee der RÃ¼ckwÃ¤rtsausbreitung

Backpropagation nutzt die **Kettenregel** der Differentialrechnung, um zu berechnen, wie stark jedes Gewicht zum Fehler beigetragen hat. Der Fehler wird dabei von der **Ausgabe zurÃ¼ck zur Eingabe** propagiert.
Jedes Gewicht \( w \) erhÃ¤lt ein individuelles **GradientenmaÃŸ**, das angibt, in welche Richtung es angepasst werden sollte.

Der Anpassungsschritt erfolgt dann mit Hilfe des Gradientenabstiegs:

![image](https://github.com/user-attachments/assets/9eedce74-ca79-4b24-8250-191afc1636d0)

Dabei ist Î· die Lernrate, die steuert, wie stark die Gewichte verÃ¤ndert werden. Ist sie zu groÃŸ, â€springtâ€œ das Netz Ã¼ber das Minimum hinaus; ist sie zu klein, dauert das Lernen sehr lange.

![image](https://github.com/user-attachments/assets/7c2fa529-b1e3-4d97-85d4-182e51366c2a)

*Abbildung 12: Backpropagation in einem neuronalen Netz â€“ Quelle: GeeksforGeeks (2023)*



### Beispiel: Spam-Klassifikation mit einem MLP

Ein **Mehrschicht-Perzeptron (MLP)** soll erkennen, ob eine E-Mail Spam ist. In der Trainingsphase erhÃ¤lt das Netz hunderte Beispiele mit Labels:

- â€Spamâ€œ  
- â€Kein Spamâ€œ

Der Ablauf:

1. Vorhersage durch das Netz  
2. Vergleich mit dem Label  
3. Fehlerberechnung  
4. Fehler wird durch das Netz zurÃ¼ckgeleitet  
5. Gewichte werden aktualisiert

Mit jeder Iteration verbessert sich die Erkennung. Das Netz lernt, welche Merkmalskombinationen typisch fÃ¼r Spam sind â€“ z.â€¯B. bestimmte WÃ¶rter im Betreff.



### Bedeutung fÃ¼r moderne Netze

**Backpropagation** ist das HerzstÃ¼ck nahezu aller modernen neuronalen Netze:

- **MLPs**
- **Convolutional Neural Networks (CNNs)**
- **Recurrent Neural Networks (RNNs)**
- u.â€¯v.â€¯m.

Ohne diesen Algorithmus wÃ¤re das effiziente Training tiefer Modelle kaum mÃ¶glich.

### Erweiterte Optimierungsstrategien

Zur Verbesserung des Lernverhaltens kommen hÃ¤ufig zusÃ¤tzliche Methoden zum Einsatz:

- **Momentum:** beschleunigt den Lernprozess  
- **Adam (Adaptive Moment Estimation):** kombiniert Momentum und RMSprop  
- **Early Stopping:** verhindert Ãœberanpassung durch Abbruch bei stagnierender Validierungsleistung

> Backpropagation + geeignete Optimierungsstrategien = Grundlage moderner Deep Learning Systeme

---

## 6.3 Tiefe neuronale Netze (Deep Neural Networks)

Tiefe neuronale Netze â€“ hÃ¤ufig als **Deep Neural Networks (DNNs)** bezeichnet â€“ bilden das HerzstÃ¼ck moderner Deep-Learning-Anwendungen. Sie erweitern klassische kÃ¼nstliche neuronale Netze (ANNs) um eine **deutlich grÃ¶ÃŸere Anzahl an versteckten Schichten (Hidden Layers)**.

WÃ¤hrend einfache Feedforward-Netze meist nur eine oder zwei versteckte Schichten besitzen, verwenden DNNs oft **dutzende Layer**, um zunehmend komplexere Merkmale zu lernen.



### Merkmale tiefer Netze

- **Hierarchisches Lernen:**  
  FrÃ¼here Schichten lernen einfache Merkmale (z.â€¯B. Kanten, Farben). SpÃ¤tere Schichten kombinieren diese zu komplexeren ReprÃ¤sentationen (z.â€¯B. Gesichter, Objekte, Sprache).

- **NichtlinearitÃ¤t durch Aktivierungsfunktionen:**  
  HÃ¤ufig eingesetzt: **ReLU (Rectified Linear Unit)**  
  Vorteile:
  - Vermeidet das Problem des **verschwindenden Gradienten**
  - FÃ¼hrt zu schnellerer Konvergenz beim Lernen

- **Hoher Bedarf an Rechenleistung und Daten:**  
  - Erfordert **groÃŸe Mengen gelabelter Daten** (z.â€¯B. Millionen Bilder)
  - Training erfolgt auf leistungsstarker Hardware: **GPU** oder **TPU**



### Vergleich: Konventionelles ML vs. Deep Learning vs. LLMs

| Merkmal                  | Traditionelles ML | Deep Learning (DNNs) | LLMs (z.â€¯B. ChatGPT) |
|--------------------------|-------------------|------------------------|-----------------------|
| Trainingsdatenmenge      | GroÃŸ              | GroÃŸ                   | Sehr groÃŸ             |
| Feature Engineering      | Manuell           | Automatisch            | Automatisch           |
| ModellkomplexitÃ¤t        | Begrenzt          | Hoch                   | Extrem hoch           |
| Interpretierbarkeit      | Gut               | Schwach                | Sehr schwach          |
| Leistung                 | MittelmÃ¤ÃŸig       | Hoch                   | Sehr hoch             |
| Hardwareanforderungen    | Gering            | Hoch                   | Sehr hoch             |

*Quelle: 430_DL_DNN, Seite 24*



### Anwendungen tiefer Netze

DNNs kommen in vielen Bereichen zum Einsatz:

- ğŸ—£ **Sprachverarbeitung**  
  *Beispiele:* Google Translate, ChatGPT, Alexa

- ğŸ©º **Medizinische Bildanalyse**  
  *Beispiel:* Erkennung von Tumoren oder Anomalien in RÃ¶ntgenbildern

- ğŸ’³ **Finanzwesen**  
  *Beispiel:* Betrugserkennung bei Kreditkartentransaktionen

- ğŸš— **Autonomes Fahren**  
  *Beispiel:* Bilderkennung, Objekterkennung, Sensorfusion

- ğŸ“· **Bild- und Objekterkennung**  
  *Beispiel:* Klassifikation in der Industrie, Sicherheitsanwendungen



> Tiefe neuronale Netze sind heute aus der KI nicht mehr wegzudenken â€“ sie liefern die Grundlage fÃ¼r viele der fortschrittlichsten Technologien unserer Zeit.

---

## 6.4 Convolutional Neural Networks (CNNs)

**Convolutional Neural Networks (CNNs)** sind speziell fÃ¼r die Verarbeitung visueller Daten (z.â€¯B. Bilder, Videos) entwickelte tiefe neuronale Netze. Ihre Architektur ermÃ¶glicht es, **lokale visuelle Merkmale** automatisch zu erkennen und schrittweise zu abstrahieren â€“ ideal fÃ¼r Klassifikations-, Erkennungs- und Segmentierungsaufgaben.

Im Gegensatz zu vollstÃ¤ndig verbundenen Netzen nutzen CNNs **Faltungsschichten (Convolutional Layers)** und **Pooling-Schichten**, wodurch die Anzahl der Parameter und die KomplexitÃ¤t reduziert wird.



### Architektur und Datenfluss

![image](https://github.com/user-attachments/assets/5c88fbfa-d8b1-4841-8480-c0872d347367)
 
*Abbildung 13: CNN-Aufbau von der Eingabe bis zur Klassifikation â€“ Quelle: MathWorks*

**Ablauf eines CNNs:**

Ein Convolutional Neural Network (CNN) verarbeitet Bilddaten in mehreren aufeinanderfolgenden Schritten. ZunÃ¤chst wird das Eingabebild durch Faltungsschichten geleitet, in denen Filter lokale Merkmale wie Kanten oder Formen erkennen. AnschlieÃŸend reduziert eine Pooling-Schicht die BildgrÃ¶ÃŸe, wobei wichtige Informationen erhalten bleiben. Dieser Prozess â€“ bestehend aus Faltung, Aktivierungsfunktion (ReLU) und Pooling â€“ wird mehrfach wiederholt, um zunehmend komplexere Merkmale zu extrahieren.

Die daraus entstehenden Merkmalskarten werden anschlieÃŸend durch eine Flatten-Schicht in einen Vektor Ã¼berfÃ¼hrt und an vollstÃ¤ndig verbundene Neuronen (Dense Layer) Ã¼bergeben. Diese fÃ¼hren auf Basis der extrahierten Merkmale die Klassifikation durch. Am Ende sorgt eine Softmax-Schicht dafÃ¼r, dass das Netzwerk eine Wahrscheinlichkeitsverteilung Ã¼ber alle mÃ¶glichen Klassen (z.â€¯B. Auto, LKW, Fahrrad) ausgibt.



### Feature Learning & Klassifikation

Die CNN-Architektur lÃ¤sst sich in zwei Hauptphasen gliedern:

- **Feature Learning:**  
  Merkmale werden automatisch erkannt â€“ vom Pixel Ã¼ber Kanten bis zu komplexen Objekten

- **Classification:**  
  In der vollstÃ¤ndig verbundenen Endphase wird entschieden, zu welcher Klasse das Bild gehÃ¶rt â€“ meist durch **Softmax**.



### Vorteile von CNNs

âœ… **LokalitÃ¤t:** Durch Filter beschrÃ¤nkt auf kleine Bildausschnitte  
âœ… **Parameterersparnis:** Gewichtsteilung reduziert Rechenaufwand  
âœ… **Translationstoleranz:** Pooling macht das Netz robust gegenÃ¼ber Objektverschiebung  
âœ… **Hohe Genauigkeit:** Besonders bei Bildklassifikation & Objekterkennung



### Typische Einsatzgebiete

- ğŸ“¸ Bildklassifikation (z.â€¯B. ImageNet)
- ğŸ” Objekterkennung (z.â€¯B. YOLO, Faster R-CNN)
- ğŸ§  Medizinische Bilddiagnostik (z.â€¯B. Tumorerkennung)
- ğŸš— Autonomes Fahren (z.â€¯B. Verkehrsschilderkennung)
- ğŸ“¹ Videoanalyse & Gesichtserkennung

---

## 6.5 NatÃ¼rliche Sprachverarbeitung (NLP)

Die natÃ¼rliche Sprachverarbeitung (Natural Language Processing, kurz: NLP) ist ein zentrales Anwendungsfeld der kÃ¼nstlichen Intelligenz, das sich mit der automatisierten Analyse, Interpretation und Generierung von menschlicher Sprache beschÃ¤ftigt. Ziel von NLP-Systemen ist es, Texte oder gesprochene Sprache so zu verarbeiten, dass Computer deren Inhalte â€verstehenâ€œ und sinnvoll darauf reagieren kÃ¶nnen.

### Grundlagen und Anwendungsbereiche

NLP basiert auf linguistischen Regeln sowie statistischen und maschinellen Lernverfahren. Dabei werden Texte zunÃ¤chst in ihre Bestandteile zerlegt und schrittweise verarbeitet. Typische Aufgaben der natÃ¼rlichen Sprachverarbeitung sind:

- **Tokenisierung:** Zerlegung eines Textes in einzelne WÃ¶rter oder SÃ¤tze.  
- **Lemmatisierung und Stemming:** Reduktion von WÃ¶rtern auf ihre Grundform (z.â€¯B. â€liefâ€œ â†’ â€laufenâ€œ).  
- **Part-of-Speech-Tagging:** Bestimmung der Wortarten (z.â€¯B. Substantiv, Verb).  
- **Parsing:** Analyse der grammatikalischen Struktur eines Satzes.  
- **Named Entity Recognition (NER):** Erkennung von Eigennamen, Orten oder Zeitangaben.

Diese Schritte bilden die Grundlage fÃ¼r komplexere Anwendungen wie automatische Ãœbersetzung, Chatbots, Sentiment-Analyse oder Textzusammenfassungen.

### Sprachmodelle und moderne Architektur: Transformer

Moderne NLP-Systeme basieren Ã¼berwiegend auf neuronalen Netzen, insbesondere Transformer-Architekturen. Diese gelten seit 2017 als Standard und bilden die Grundlage fÃ¼r viele groÃŸe Sprachmodelle wie BERT, GPT oder T5.

Die folgende Abbildung zeigt den schematischen Aufbau eines klassischen Transformers:

<img width="267" alt="GENAI-1 151ded5440b4c997bac0642ec669a00acff2cca1" src="https://github.com/user-attachments/assets/219a5ff8-d976-4765-b962-f68cf7c80153" />

*Abbildung 14: Aufbau eines Transformer-Modells mit Encoder und Decoder -  Quelle: Amazon Web Services (2024): â€Was sind Transformer in der kÃ¼nstlichen Intelligenz?â€œ*

Der Transformer besteht aus zwei Hauptkomponenten:

- **Encoder (links):** Wandelt die Eingabesequenz (Input Embedding + Positionskodierung) durch mehrschichtige Verarbeitung in eine abstrakte ReprÃ¤sentation um.  
- **Decoder (rechts):** Generiert auf Basis dieser ReprÃ¤sentation ein Ausgabeergebnis (z.â€¯B. Ãœbersetzung).

Die wichtigsten Elemente im Modell sind:

- **Multi-Head Attention:** Der Kernmechanismus, um Kontextbeziehungen zwischen WÃ¶rtern zu erkennen â€“ auch Ã¼ber groÃŸe Distanzen im Satz.  
- **Masked Multi-Head Attention:** Im Decoder sorgt diese Variante dafÃ¼r, dass bei der Generierung eines Satzes nur bereits erzeugte WÃ¶rter berÃ¼cksichtigt werden (KausalitÃ¤t).  
- **Feed Forward Layer:** ZustÃ¤ndig fÃ¼r nicht-lineare Transformationen innerhalb jeder Ebene.  
- **Add & Norm:** Normalisierungsschritte zur Stabilisierung des Trainings.  
- **Positional Encoding:** Da das Modell selbst keine Reihenfolge kennt, wird die Wortposition explizit codiert.

### Bedeutung in der Praxis

NLP ist heute in zahlreichen digitalen Anwendungen allgegenwÃ¤rtig â€“ von Rechtschreibkorrekturen Ã¼ber automatische Ãœbersetzungen (z.â€¯B. DeepL, Google Translate) bis hin zu Sprachassistenten wie Siri oder Alexa. Auch in der Finanzbranche, im Gesundheitswesen und in der juristischen Dokumentenanalyse gewinnt NLP zunehmend an Bedeutung.

---

## 6.6 GroÃŸe Sprachmodelle und Embeddings (LLMs)

In den letzten Jahren haben sich sogenannte groÃŸe Sprachmodelle (engl. â€Large Language Modelsâ€œ â€“ kurz: LLMs) zu einem zentralen Bestandteil moderner KI-Systeme entwickelt. Diese Modelle sind in der Lage, menschliche Sprache auf beeindruckende Weise zu verstehen und sogar eigenstÃ¤ndig Texte zu generieren. Grundlage dafÃ¼r ist die Transformer-Architektur, auf die bereits im vorherigen Kapitel eingegangen wurde.

### Was genau sind LLMs?

GroÃŸe Sprachmodelle bestehen aus neuronalen Netzwerken mit mehreren Milliarden Parametern. Trainiert werden sie auf riesigen Mengen an Text â€“ darunter BÃ¼cher, Webseiten, ForenbeitrÃ¤ge oder Wikipedia-EintrÃ¤ge. WÃ¤hrend des Trainings lernen sie, Wahrscheinlichkeiten fÃ¼r Wortfolgen vorherzusagen. Das klingt zunÃ¤chst unspektakulÃ¤r, fÃ¼hrt aber dazu, dass sie in der Lage sind, Sprache erstaunlich gut nachzubilden â€“ oft so Ã¼berzeugend, dass man meinen kÃ¶nnte, ein Mensch habe den Text geschrieben.

Bekannte Beispiele fÃ¼r solche Modelle sind **GPT** (von OpenAI), **BERT** (von Google) oder **LLaMA** (von Meta). Viele dieser Modelle sind Ã¶ffentlich zugÃ¤nglich oder in Plattformen wie Chatbots oder Suchmaschinen integriert.

### Die Rolle von Embeddings

Damit ein Sprachmodell mit WÃ¶rtern Ã¼berhaupt arbeiten kann, mÃ¼ssen diese zunÃ¤chst mathematisch dargestellt werden â€“ und zwar in Form sogenannter **Embeddings**. Dabei wird jedes Wort (oder auch ein Wortbestandteil) als ein mehrdimensionaler Vektor dargestellt. Der Clou: WÃ¶rter mit Ã¤hnlicher Bedeutung liegen in diesem Vektorraum nÃ¤her beieinander als solche mit unterschiedlicher Bedeutung.

FrÃ¼here Verfahren wie **Word2Vec** oder **GloVe** haben fÃ¼r jedes Wort einen festen Vektor erzeugt â€“ unabhÃ¤ngig vom Kontext. Moderne Modelle wie **BERT** oder **GPT** berÃ¼cksichtigen dagegen den jeweiligen Satzzusammenhang. So bekommt das Wort *â€Bankâ€œ* in einem Satz Ã¼ber Geld eine andere ReprÃ¤sentation als in einem Satz Ã¼ber einen Park.

### Aufbau und Lernprozess

Ein LLM besteht aus vielen Ã¼bereinandergeschichteten **Transformer-BlÃ¶cken**. Jeder dieser BlÃ¶cke verarbeitet die Eingabedaten und gibt sie an die nÃ¤chste Ebene weiter. Dabei werden die Beziehungen zwischen WÃ¶rtern analysiert und gewichtet â€“ ein Mechanismus, der als **Self-Attention** bekannt ist.

Der Lernprozess ist zweigeteilt:

- **Pretraining**: Das Modell wird allgemein trainiert, um Sprache, Grammatik und Weltwissen zu lernen.  
- **Finetuning**: Danach kann es gezielt auf bestimmte Aufgaben vorbereitet werden, z.â€¯B. fÃ¼r den Einsatz in der Medizin, im Recht oder im Kundenservice.

### Wichtig zu wissen

Diese Systeme arbeiten nicht â€intelligentâ€œ im menschlichen Sinne. Sie haben **kein eigenes VerstÃ¤ndnis**, sondern verarbeiten Sprache rein statistisch. Trotzdem sind die Ergebnisse oft so gut, dass sie in vielen Bereichen einen echten Mehrwert bieten.

---

## 6.7 Prompt Engineering und AnwendungsmÃ¶glichkeiten

Ein Aspekt im Umgang mit groÃŸen Sprachmodellen (LLMs) ist die sogenannte **â€Prompt-Steuerungâ€œ**. Dabei geht es darum, wie man einem Modell Anweisungen gibt â€“ also wie man die Eingabeformulierung (den Prompt) gestaltet, um mÃ¶glichst sinnvolle, prÃ¤zise oder kreative Antworten zu erhalten. Dieses Vorgehen wird unter dem Begriff **Prompt Engineering** zusammengefasst.

### Warum ist Prompt Engineering wichtig?

Sprachmodelle reagieren sehr sensibel auf die Art und Weise, wie Fragen gestellt oder Aufgaben beschrieben werden. Schon kleine Ã„nderungen in der Formulierung kÃ¶nnen zu vÃ¶llig unterschiedlichen Ergebnissen fÃ¼hren. Wer gute Resultate mÃ¶chte, muss daher lernen, mit dem Modell klar, zielgerichtet und strategisch zu kommunizieren.

Ein einfaches Beispiel:

- â€ErklÃ¤re mir kurz, was ein neuronales Netz ist.â€œ  
- â€Stell dir vor, du erklÃ¤rst einem SchÃ¼ler in der 9. Klasse, was ein neuronales Netz macht. Bitte mÃ¶glichst anschaulich.â€œ

Beide Prompts haben das gleiche Ziel, doch die zweite Variante liefert oft die verstÃ¤ndlichere Antwort â€“ weil sie dem Modell mehr Kontext und eine klare Rolle vorgibt.

### Techniken und Strategien

Inzwischen gibt es eine Reihe von erprobten Methoden, um Prompts gezielt zu gestalten. Hier ein paar wichtige Beispiele:

- **Few-Shot Learning:** Man zeigt dem Modell vorab ein paar Beispiele (z.â€¯B. Fragen und Antworten), bevor man die eigentliche Aufgabe stellt.  
- **Chain-of-Thought Prompting:** Das Modell wird aufgefordert, einen Denkprozess in mehreren Schritten durchzufÃ¼hren, bevor es ein Ergebnis nennt. Besonders hilfreich bei komplexen Aufgaben oder Rechenwegen.  
- **Role-Based Prompting:** Dem Modell wird eine bestimmte Rolle zugewiesen (z.â€¯B. â€Du bist ein IT-Experteâ€œ oder â€Du schreibst als Lehrerâ€œ), um Stil und Inhalt zu beeinflussen.  
- **Prompt Chaining:** Komplexe Aufgaben werden in kleinere Teilschritte zerlegt, die nacheinander abgearbeitet werden. Das verbessert oft die QualitÃ¤t und Nachvollziehbarkeit.

### Vorischt

- Sprachmodelle neigen gelegentlich zu sogenannten **Halluzinationen** â€“ also erfundenen oder sachlich falschen Informationen, die aber sprachlich Ã¼berzeugend klingen.  
- Bei schlecht formulierten Prompts kann es zu **Fehlinterpretationen oder nicht reproduzierbaren Ergebnissen** kommen.  
- Zudem besteht die Gefahr sogenannter **Prompt Injections**, bei denen ein Modell gezielt durch manipulierte Eingaben zu unerwÃ¼nschtem Verhalten gebracht wird.

---

## Quellen

1. ORDIX Blog (2021): Einstieg in neuronale Netze mit TensorFlow und Keras  
   [https://blog.ordix.de/einstieg-in-neuronale-netze-mit-tensorflow-und-keras](https://blog.ordix.de/einstieg-in-neuronale-netze-mit-tensorflow-und-keras)

2. Rosenblatt, F. (1958): *The Perceptron*  
   Psychological Review, Vol. 65, No. 6

3. Goodfellow, I., Bengio, Y., Courville, A. (2016): *Deep Learning*  
   [https://www.deeplearningbook.org/](https://www.deeplearningbook.org/)

4. Mitchell, T. (1997): *Machine Learning*, McGraw-Hill Education

5. Kriegel, H.-P. et al. (2020): *KÃ¼nstliche Intelligenz: Grundlagen intelligenter Systeme*, Springer Vieweg

6. Wikipedia (2025): [KÃ¼nstliches neuronales Netz](https://de.wikipedia.org/wiki/KÃ¼nstliches_neuronales_Netz)

7. GeeksforGeeks (2023): [Backpropagation in Neural Network](https://www.geeksforgeeks.org/backpropagation-in-neural-network/)

8. Amazon Web Services (2024): *Was sind Transformer in der kÃ¼nstlichen Intelligenz? (Abbildung 16)*  
   https://aws.amazon.com/de/what-is/transformers-in-artificial-intelligence/

9. Vaswani, A. et al. (2017): *Attention is All You Need.*  
   https://arxiv.org/abs/1706.03762

10. OpenAI (2023): *Best Practices for Prompt Engineering with GPT.*  
    https://platform.openai.com/docs/guides/gpt-best-practices
11. MathWorks (o.â€¯J.): *Convolutional Neural Networks â€“ Aufbau eines CNNs von der Eingabe bis zur Klassifikation * https://de.mathworks.com/discovery/convolutional-neural-network.html
 
