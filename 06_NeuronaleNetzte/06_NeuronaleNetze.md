# 6. Neuronale Netze

Neuronale Netze sind ein zentraler Bestandteil moderner KI-Systeme. Sie sind inspiriert vom menschlichen Gehirn, bestehen jedoch aus **k√ºnstlichen Neuronen**, die Informationen verarbeiten, weiterleiten und lernen, Muster in Daten zu erkennen.

---

## 6.1 Grundidee k√ºnstlicher Neuronen

Ein k√ºnstliches Neuron erh√§lt mehrere Eingangswerte, multipliziert sie mit Gewichtungen, summiert die Ergebnisse auf und entscheidet √ºber eine **Aktivierungsfunktion**, ob und wie stark es ‚Äûanspringt‚Äú.

### Aufbau eines k√ºnstlichen Neurons (Perzeptron):

Das Perzeptron ist das √§lteste und zugleich einfachste Modell eines k√ºnstlichen Neurons. Es wurde Ende der 1950er Jahre von Frank Rosenblatt entwickelt und kann lineare Entscheidungsgrenzen erlernen. Ein Perzeptron besteht aus:

- **Eingaben:** \( x_1, x_2, ..., x_n \)  
- **Gewichte:** \( w_1, w_2, ..., w_n \)  
- **Berechnung:**  
 z =   ‚àë wi xi + b (mit Bias b) wobei \( b \) der **Bias** ist

- **Aktivierung:** Einer Aktivierungsfunktion (z.B. ein Schwellenwert), die entscheidet, ob das Neuron ‚Äûfeuert‚Äú


Das Perzeptron lernt durch Anpassung der Gewichte, ob ein Datenpunkt zur Klasse 1 oder 0 geh√∂rt. Es kann jedoch nur linear separierbare Probleme l√∂sen.



## Netzstruktur: Von der Eingabe zur Vorhersage

Ein einzelnes Neuron ist nicht ausreichend f√ºr komplexe Aufgaben. Erst durch das **Verkn√ºpfen mehrerer Neuronen zu Netzwerken** entstehen leistungsf√§hige Strukturen:

### Typische Architektur eines neuronalen Netzes:

- **Eingabeschicht:** Nimmt Rohdaten auf (z.‚ÄØB. Pixel, Sensordaten)
- **Versteckte Schichten (Hidden Layers):** Transformieren und abstrahieren Merkmale
- **Ausgabeschicht:** Gibt die finale Vorhersage aus (z.‚ÄØB. Kategorie, Wert)

Netze mit mehreren versteckten Schichten werden als **Mehrschicht-Perzeptrons (MLP)** bezeichnet. Sie geh√∂ren zur Klasse der **Feedforward-Netze**, bei denen Informationen nur in eine Richtung flie√üen ‚Äì von der Eingabe zur Ausgabe.

![image](https://github.com/user-attachments/assets/8d540b6c-2be0-49f7-bbd7-b2d951789290)

*Abbildung 11: Feedforward-Netz mit 2 Hidden Layers ‚Äì Quelle: ORDIX Blog, 2021*


**Erkl√§rung:**  

Die Eingabeschicht (blau) nimmt die Merkmale x1 bis x5 auf. Diese werden durch zehn Neuronen in der ersten verdeckten Schicht verarbeitet, anschlie√üend durch f√ºnf weitere Neuronen in der zweiten versteckten Schicht weitergegeben und schlie√ülich zu einer Vorhersage y1 in der Ausgabeschicht (gr√ºn) zusammengef√ºhrt. Jede Verbindung ist mit einem Gewicht versehen, das beim Lernen angepasst wird.




## Anwendung: Bilderkennung

Ein neuronales Netz kann z.‚ÄØB. lernen, **handgeschriebene Ziffern (0‚Äì9)** zu erkennen:

1. **Eingabeschicht:** nimmt Pixelwerte des Bildes auf  
2. **Versteckte Schichten:** extrahieren Muster wie Kanten oder Kurven  
3. **Ausgabeschicht:** entscheidet sich f√ºr die wahrscheinlichste Ziffer



> Ein neuronales Netz lernt durch viele Beispiele, relevante Merkmale in den Daten zu erkennen ‚Äì ganz ohne explizit programmierte Regeln.

---

## 6.2 Lernen mit Backpropagation

Damit ein neuronales Netz nicht nur zuf√§llige Ausgaben produziert, sondern gezielt Muster erkennen kann, muss es aus Beispielen lernen. Das zentrale Trainingsverfahren f√ºr Feedforward-Netze ist der **Backpropagation-Algorithmus** ‚Äì auf Deutsch: R√ºckw√§rtsausbreitung des Fehlers.

### Ziel: Fehler minimieren

Der Lernprozess basiert auf dem Vergleich zwischen der tats√§chlichen Ausgabe \( \hat{y} \) des Netzes und dem Zielwert \( y \). Die Differenz wird durch eine **Fehlerfunktion (Loss Function)** quantifiziert, z.‚ÄØB.:

![image](https://github.com/user-attachments/assets/71d425bc-95e2-435b-ad2a-7f666f5ab9ad)


Ziel ist es, die Summe der Fehler √ºber alle Trainingsbeispiele hinweg zu minimieren. Dazu passt das Netz seine **Gewichte** iterativ an.



### Idee der R√ºckw√§rtsausbreitung

Backpropagation nutzt die **Kettenregel** der Differentialrechnung, um zu berechnen, wie stark jedes Gewicht zum Fehler beigetragen hat. Der Fehler wird dabei von der **Ausgabe zur√ºck zur Eingabe** propagiert.
Jedes Gewicht \( w \) erh√§lt ein individuelles **Gradientenma√ü**, das angibt, in welche Richtung es angepasst werden sollte.

Der Anpassungsschritt erfolgt dann mit Hilfe des Gradientenabstiegs:

![image](https://github.com/user-attachments/assets/9eedce74-ca79-4b24-8250-191afc1636d0)

Dabei ist Œ∑ die Lernrate, die steuert, wie stark die Gewichte ver√§ndert werden. Ist sie zu gro√ü, ‚Äûspringt‚Äú das Netz √ºber das Minimum hinaus; ist sie zu klein, dauert das Lernen sehr lange.

![image](https://github.com/user-attachments/assets/7c2fa529-b1e3-4d97-85d4-182e51366c2a)

*Abbildung 12: Backpropagation in einem neuronalen Netz ‚Äì Quelle: GeeksforGeeks (2023)*



### Beispiel: Spam-Klassifikation mit einem MLP

Ein **Mehrschicht-Perzeptron (MLP)** soll erkennen, ob eine E-Mail Spam ist. In der Trainingsphase erh√§lt das Netz hunderte Beispiele mit Labels:

- ‚ÄûSpam‚Äú  
- ‚ÄûKein Spam‚Äú

Der Ablauf:

1. Vorhersage durch das Netz  
2. Vergleich mit dem Label  
3. Fehlerberechnung  
4. Fehler wird durch das Netz zur√ºckgeleitet  
5. Gewichte werden aktualisiert

Mit jeder Iteration verbessert sich die Erkennung. Das Netz lernt, welche Merkmalskombinationen typisch f√ºr Spam sind ‚Äì z.‚ÄØB. bestimmte W√∂rter im Betreff.



### Bedeutung f√ºr moderne Netze

**Backpropagation** ist das Herzst√ºck nahezu aller modernen neuronalen Netze:

- **MLPs**
- **Convolutional Neural Networks (CNNs)**
- **Recurrent Neural Networks (RNNs)**
- u.‚ÄØv.‚ÄØm.

Ohne diesen Algorithmus w√§re das effiziente Training tiefer Modelle kaum m√∂glich.

### Erweiterte Optimierungsstrategien

Zur Verbesserung des Lernverhaltens kommen h√§ufig zus√§tzliche Methoden zum Einsatz:

- **Momentum:** beschleunigt den Lernprozess  
- **Adam (Adaptive Moment Estimation):** kombiniert Momentum und RMSprop  
- **Early Stopping:** verhindert √úberanpassung durch Abbruch bei stagnierender Validierungsleistung

> Backpropagation + geeignete Optimierungsstrategien = Grundlage moderner Deep Learning Systeme

---

## 6.3 Tiefe neuronale Netze (Deep Neural Networks)

Tiefe neuronale Netze ‚Äì h√§ufig als **Deep Neural Networks (DNNs)** bezeichnet ‚Äì bilden das Herzst√ºck moderner Deep-Learning-Anwendungen. Sie erweitern klassische k√ºnstliche neuronale Netze (ANNs) um eine **deutlich gr√∂√üere Anzahl an versteckten Schichten (Hidden Layers)**.

W√§hrend einfache Feedforward-Netze meist nur eine oder zwei versteckte Schichten besitzen, verwenden DNNs oft **dutzende Layer**, um zunehmend komplexere Merkmale zu lernen.



### Merkmale tiefer Netze

- **Hierarchisches Lernen:**  
  Fr√ºhere Schichten lernen einfache Merkmale (z.‚ÄØB. Kanten, Farben). Sp√§tere Schichten kombinieren diese zu komplexeren Repr√§sentationen (z.‚ÄØB. Gesichter, Objekte, Sprache).

- **Nichtlinearit√§t durch Aktivierungsfunktionen:**  
  H√§ufig eingesetzt: **ReLU (Rectified Linear Unit)**  
  Vorteile:
  - Vermeidet das Problem des **verschwindenden Gradienten**
  - F√ºhrt zu schnellerer Konvergenz beim Lernen

- **Hoher Bedarf an Rechenleistung und Daten:**  
  - Erfordert **gro√üe Mengen gelabelter Daten** (z.‚ÄØB. Millionen Bilder)
  - Training erfolgt auf leistungsstarker Hardware: **GPU** oder **TPU**



### Vergleich: Konventionelles ML vs. Deep Learning vs. LLMs

| Merkmal                  | Traditionelles ML | Deep Learning (DNNs) | LLMs (z.‚ÄØB. ChatGPT) |
|--------------------------|-------------------|------------------------|-----------------------|
| Trainingsdatenmenge      | Gro√ü              | Gro√ü                   | Sehr gro√ü             |
| Feature Engineering      | Manuell           | Automatisch            | Automatisch           |
| Modellkomplexit√§t        | Begrenzt          | Hoch                   | Extrem hoch           |
| Interpretierbarkeit      | Gut               | Schwach                | Sehr schwach          |
| Leistung                 | Mittelm√§√üig       | Hoch                   | Sehr hoch             |
| Hardwareanforderungen    | Gering            | Hoch                   | Sehr hoch             |

*Quelle: 430_DL_DNN, Seite 24*



### Anwendungen tiefer Netze

DNNs kommen in vielen Bereichen zum Einsatz:

- üó£ **Sprachverarbeitung**  
  *Beispiele:* Google Translate, ChatGPT, Alexa

- ü©∫ **Medizinische Bildanalyse**  
  *Beispiel:* Erkennung von Tumoren oder Anomalien in R√∂ntgenbildern

- üí≥ **Finanzwesen**  
  *Beispiel:* Betrugserkennung bei Kreditkartentransaktionen

- üöó **Autonomes Fahren**  
  *Beispiel:* Bilderkennung, Objekterkennung, Sensorfusion

- üì∑ **Bild- und Objekterkennung**  
  *Beispiel:* Klassifikation in der Industrie, Sicherheitsanwendungen



> Tiefe neuronale Netze sind heute aus der KI nicht mehr wegzudenken ‚Äì sie liefern die Grundlage f√ºr viele der fortschrittlichsten Technologien unserer Zeit.

---

## 6.4 Convolutional Neural Networks (CNNs)

**Convolutional Neural Networks (CNNs)** sind speziell f√ºr die Verarbeitung visueller Daten (z.‚ÄØB. Bilder, Videos) entwickelte tiefe neuronale Netze. Ihre Architektur erm√∂glicht es, **lokale visuelle Merkmale** automatisch zu erkennen und schrittweise zu abstrahieren ‚Äì ideal f√ºr Klassifikations-, Erkennungs- und Segmentierungsaufgaben.

Im Gegensatz zu vollst√§ndig verbundenen Netzen nutzen CNNs **Faltungsschichten (Convolutional Layers)** und **Pooling-Schichten**, wodurch die Anzahl der Parameter und die Komplexit√§t reduziert wird.



### Architektur und Datenfluss

![image](https://github.com/user-attachments/assets/5c88fbfa-d8b1-4841-8480-c0872d347367)
 
*Abbildung 13: CNN-Aufbau von der Eingabe bis zur Klassifikation ‚Äì Quelle: MathWorks*

**Ablauf eines CNNs:**

Ein Convolutional Neural Network (CNN) verarbeitet Bilddaten in mehreren aufeinanderfolgenden Schritten. Zun√§chst wird das Eingabebild durch Faltungsschichten geleitet, in denen Filter lokale Merkmale wie Kanten oder Formen erkennen. Anschlie√üend reduziert eine Pooling-Schicht die Bildgr√∂√üe, wobei wichtige Informationen erhalten bleiben. Dieser Prozess ‚Äì bestehend aus Faltung, Aktivierungsfunktion (ReLU) und Pooling ‚Äì wird mehrfach wiederholt, um zunehmend komplexere Merkmale zu extrahieren.

Die daraus entstehenden Merkmalskarten werden anschlie√üend durch eine Flatten-Schicht in einen Vektor √ºberf√ºhrt und an vollst√§ndig verbundene Neuronen (Dense Layer) √ºbergeben. Diese f√ºhren auf Basis der extrahierten Merkmale die Klassifikation durch. Am Ende sorgt eine Softmax-Schicht daf√ºr, dass das Netzwerk eine Wahrscheinlichkeitsverteilung √ºber alle m√∂glichen Klassen (z.‚ÄØB. Auto, LKW, Fahrrad) ausgibt.



### Feature Learning & Klassifikation

Die CNN-Architektur l√§sst sich in zwei Hauptphasen gliedern:

- **Feature Learning:**  
  Merkmale werden automatisch erkannt ‚Äì vom Pixel √ºber Kanten bis zu komplexen Objekten

- **Classification:**  
  In der vollst√§ndig verbundenen Endphase wird entschieden, zu welcher Klasse das Bild geh√∂rt ‚Äì meist durch **Softmax**.



### Vorteile von CNNs

‚úÖ **Lokalit√§t:** Durch Filter beschr√§nkt auf kleine Bildausschnitte  
‚úÖ **Parameterersparnis:** Gewichtsteilung reduziert Rechenaufwand  
‚úÖ **Translationstoleranz:** Pooling macht das Netz robust gegen√ºber Objektverschiebung  
‚úÖ **Hohe Genauigkeit:** Besonders bei Bildklassifikation & Objekterkennung



### Typische Einsatzgebiete

- üì∏ Bildklassifikation (z.‚ÄØB. ImageNet)
- üîç Objekterkennung (z.‚ÄØB. YOLO, Faster R-CNN)
- üß† Medizinische Bilddiagnostik (z.‚ÄØB. Tumorerkennung)
- üöó Autonomes Fahren (z.‚ÄØB. Verkehrsschilderkennung)
- üìπ Videoanalyse & Gesichtserkennung

---

## 6.5 Nat√ºrliche Sprachverarbeitung (NLP)

Die nat√ºrliche Sprachverarbeitung (Natural Language Processing, kurz: NLP) ist ein zentrales Anwendungsfeld der k√ºnstlichen Intelligenz, das sich mit der automatisierten Analyse, Interpretation und Generierung von menschlicher Sprache besch√§ftigt. Ziel von NLP-Systemen ist es, Texte oder gesprochene Sprache so zu verarbeiten, dass Computer deren Inhalte ‚Äûverstehen‚Äú und sinnvoll darauf reagieren k√∂nnen.

### Grundlagen und Anwendungsbereiche

NLP basiert auf linguistischen Regeln sowie statistischen und maschinellen Lernverfahren. Dabei werden Texte zun√§chst in ihre Bestandteile zerlegt und schrittweise verarbeitet. Typische Aufgaben der nat√ºrlichen Sprachverarbeitung sind:

- **Tokenisierung:** Zerlegung eines Textes in einzelne W√∂rter oder S√§tze.  
- **Lemmatisierung und Stemming:** Reduktion von W√∂rtern auf ihre Grundform (z.‚ÄØB. ‚Äûlief‚Äú ‚Üí ‚Äûlaufen‚Äú).  
- **Part-of-Speech-Tagging:** Bestimmung der Wortarten (z.‚ÄØB. Substantiv, Verb).  
- **Parsing:** Analyse der grammatikalischen Struktur eines Satzes.  
- **Named Entity Recognition (NER):** Erkennung von Eigennamen, Orten oder Zeitangaben.

Diese Schritte bilden die Grundlage f√ºr komplexere Anwendungen wie automatische √úbersetzung, Chatbots, Sentiment-Analyse oder Textzusammenfassungen.

### Sprachmodelle und moderne Architektur: Transformer

Moderne NLP-Systeme basieren √ºberwiegend auf neuronalen Netzen, insbesondere Transformer-Architekturen. Diese gelten seit 2017 als Standard und bilden die Grundlage f√ºr viele gro√üe Sprachmodelle wie BERT, GPT oder T5.

Die folgende Abbildung zeigt den schematischen Aufbau eines klassischen Transformers:

<img width="267" alt="GENAI-1 151ded5440b4c997bac0642ec669a00acff2cca1" src="https://github.com/user-attachments/assets/219a5ff8-d976-4765-b962-f68cf7c80153" />

*Abbildung 14: Aufbau eines Transformer-Modells mit Encoder und Decoder -  Quelle: Amazon Web Services (2024): ‚ÄûWas sind Transformer in der k√ºnstlichen Intelligenz?‚Äú*

Der Transformer besteht aus zwei Hauptkomponenten:

- **Encoder (links):** Wandelt die Eingabesequenz (Input Embedding + Positionskodierung) durch mehrschichtige Verarbeitung in eine abstrakte Repr√§sentation um.  
- **Decoder (rechts):** Generiert auf Basis dieser Repr√§sentation ein Ausgabeergebnis (z.‚ÄØB. √úbersetzung).

Die wichtigsten Elemente im Modell sind:

- **Multi-Head Attention:** Der Kernmechanismus, um Kontextbeziehungen zwischen W√∂rtern zu erkennen ‚Äì auch √ºber gro√üe Distanzen im Satz.  
- **Masked Multi-Head Attention:** Im Decoder sorgt diese Variante daf√ºr, dass bei der Generierung eines Satzes nur bereits erzeugte W√∂rter ber√ºcksichtigt werden (Kausalit√§t).  
- **Feed Forward Layer:** Zust√§ndig f√ºr nicht-lineare Transformationen innerhalb jeder Ebene.  
- **Add & Norm:** Normalisierungsschritte zur Stabilisierung des Trainings.  
- **Positional Encoding:** Da das Modell selbst keine Reihenfolge kennt, wird die Wortposition explizit codiert.

### Bedeutung in der Praxis

NLP ist heute in zahlreichen digitalen Anwendungen allgegenw√§rtig ‚Äì von Rechtschreibkorrekturen √ºber automatische √úbersetzungen (z.‚ÄØB. DeepL, Google Translate) bis hin zu Sprachassistenten wie Siri oder Alexa. Auch in der Finanzbranche, im Gesundheitswesen und in der juristischen Dokumentenanalyse gewinnt NLP zunehmend an Bedeutung.

---

## 6.6 Gro√üe Sprachmodelle und Embeddings (LLMs)

In den letzten Jahren haben sich sogenannte gro√üe Sprachmodelle (engl. ‚ÄûLarge Language Models‚Äú ‚Äì kurz: LLMs) zu einem zentralen Bestandteil moderner KI-Systeme entwickelt. Diese Modelle sind in der Lage, menschliche Sprache auf beeindruckende Weise zu verstehen und sogar eigenst√§ndig Texte zu generieren. Grundlage daf√ºr ist die Transformer-Architektur, auf die bereits im vorherigen Kapitel eingegangen wurde.

### Was genau sind LLMs?

Gro√üe Sprachmodelle bestehen aus neuronalen Netzwerken mit mehreren Milliarden Parametern. Trainiert werden sie auf riesigen Mengen an Text ‚Äì darunter B√ºcher, Webseiten, Forenbeitr√§ge oder Wikipedia-Eintr√§ge. W√§hrend des Trainings lernen sie, Wahrscheinlichkeiten f√ºr Wortfolgen vorherzusagen. Das klingt zun√§chst unspektakul√§r, f√ºhrt aber dazu, dass sie in der Lage sind, Sprache erstaunlich gut nachzubilden ‚Äì oft so √ºberzeugend, dass man meinen k√∂nnte, ein Mensch habe den Text geschrieben.

Bekannte Beispiele f√ºr solche Modelle sind **GPT** (von OpenAI), **BERT** (von Google) oder **LLaMA** (von Meta). Viele dieser Modelle sind √∂ffentlich zug√§nglich oder in Plattformen wie Chatbots oder Suchmaschinen integriert.

### Die Rolle von Embeddings

Damit ein Sprachmodell mit W√∂rtern √ºberhaupt arbeiten kann, m√ºssen diese zun√§chst mathematisch dargestellt werden ‚Äì und zwar in Form sogenannter **Embeddings**. Dabei wird jedes Wort (oder auch ein Wortbestandteil) als ein mehrdimensionaler Vektor dargestellt. Der Clou: W√∂rter mit √§hnlicher Bedeutung liegen in diesem Vektorraum n√§her beieinander als solche mit unterschiedlicher Bedeutung.

Fr√ºhere Verfahren wie **Word2Vec** oder **GloVe** haben f√ºr jedes Wort einen festen Vektor erzeugt ‚Äì unabh√§ngig vom Kontext. Moderne Modelle wie **BERT** oder **GPT** ber√ºcksichtigen dagegen den jeweiligen Satzzusammenhang. So bekommt das Wort *‚ÄûBank‚Äú* in einem Satz √ºber Geld eine andere Repr√§sentation als in einem Satz √ºber einen Park.

### Aufbau und Lernprozess

Ein LLM besteht aus vielen √ºbereinandergeschichteten **Transformer-Bl√∂cken**. Jeder dieser Bl√∂cke verarbeitet die Eingabedaten und gibt sie an die n√§chste Ebene weiter. Dabei werden die Beziehungen zwischen W√∂rtern analysiert und gewichtet ‚Äì ein Mechanismus, der als **Self-Attention** bekannt ist.

Der Lernprozess ist zweigeteilt:

- **Pretraining**: Das Modell wird allgemein trainiert, um Sprache, Grammatik und Weltwissen zu lernen.  
- **Finetuning**: Danach kann es gezielt auf bestimmte Aufgaben vorbereitet werden, z.‚ÄØB. f√ºr den Einsatz in der Medizin, im Recht oder im Kundenservice.

### Wichtig zu wissen

Diese Systeme arbeiten nicht ‚Äûintelligent‚Äú im menschlichen Sinne. Sie haben **kein eigenes Verst√§ndnis**, sondern verarbeiten Sprache rein statistisch. Trotzdem sind die Ergebnisse oft so gut, dass sie in vielen Bereichen einen echten Mehrwert bieten.

---

## 6.7 Prompt Engineering und Anwendungsm√∂glichkeiten

Ein Aspekt im Umgang mit gro√üen Sprachmodellen (LLMs) ist die sogenannte **‚ÄûPrompt-Steuerung‚Äú**. Dabei geht es darum, wie man einem Modell Anweisungen gibt ‚Äì also wie man die Eingabeformulierung (den Prompt) gestaltet, um m√∂glichst sinnvolle, pr√§zise oder kreative Antworten zu erhalten. Dieses Vorgehen wird unter dem Begriff **Prompt Engineering** zusammengefasst.

### Warum ist Prompt Engineering wichtig?

Sprachmodelle reagieren sehr sensibel auf die Art und Weise, wie Fragen gestellt oder Aufgaben beschrieben werden. Schon kleine √Ñnderungen in der Formulierung k√∂nnen zu v√∂llig unterschiedlichen Ergebnissen f√ºhren. Wer gute Resultate m√∂chte, muss daher lernen, mit dem Modell klar, zielgerichtet und strategisch zu kommunizieren.

Ein einfaches Beispiel:

- ‚ÄûErkl√§re mir kurz, was ein neuronales Netz ist.‚Äú  
- ‚ÄûStell dir vor, du erkl√§rst einem Sch√ºler in der 9. Klasse, was ein neuronales Netz macht. Bitte m√∂glichst anschaulich.‚Äú

Beide Prompts haben das gleiche Ziel, doch die zweite Variante liefert oft die verst√§ndlichere Antwort ‚Äì weil sie dem Modell mehr Kontext und eine klare Rolle vorgibt.

### Techniken und Strategien

Inzwischen gibt es eine Reihe von erprobten Methoden, um Prompts gezielt zu gestalten. Hier ein paar wichtige Beispiele:

- **Few-Shot Learning:** Man zeigt dem Modell vorab ein paar Beispiele (z.‚ÄØB. Fragen und Antworten), bevor man die eigentliche Aufgabe stellt.  
- **Chain-of-Thought Prompting:** Das Modell wird aufgefordert, einen Denkprozess in mehreren Schritten durchzuf√ºhren, bevor es ein Ergebnis nennt. Besonders hilfreich bei komplexen Aufgaben oder Rechenwegen.  
- **Role-Based Prompting:** Dem Modell wird eine bestimmte Rolle zugewiesen (z.‚ÄØB. ‚ÄûDu bist ein IT-Experte‚Äú oder ‚ÄûDu schreibst als Lehrer‚Äú), um Stil und Inhalt zu beeinflussen.  
- **Prompt Chaining:** Komplexe Aufgaben werden in kleinere Teilschritte zerlegt, die nacheinander abgearbeitet werden. Das verbessert oft die Qualit√§t und Nachvollziehbarkeit.

### Vorischt

- Sprachmodelle neigen gelegentlich zu sogenannten **Halluzinationen** ‚Äì also erfundenen oder sachlich falschen Informationen, die aber sprachlich √ºberzeugend klingen.  
- Bei schlecht formulierten Prompts kann es zu **Fehlinterpretationen oder nicht reproduzierbaren Ergebnissen** kommen.  
- Zudem besteht die Gefahr sogenannter **Prompt Injections**, bei denen ein Modell gezielt durch manipulierte Eingaben zu unerw√ºnschtem Verhalten gebracht wird.

---

## Quellen

1. ORDIX Blog (2021): Einstieg in neuronale Netze mit TensorFlow und Keras  
   [https://blog.ordix.de/einstieg-in-neuronale-netze-mit-tensorflow-und-keras](https://blog.ordix.de/einstieg-in-neuronale-netze-mit-tensorflow-und-keras)

2. Rosenblatt, F. (1958): *The Perceptron*  
   Psychological Review, Vol. 65, No. 6

3. Goodfellow, I., Bengio, Y., Courville, A. (2016): *Deep Learning*  
   [https://www.deeplearningbook.org/](https://www.deeplearningbook.org/)

4. Mitchell, T. (1997): *Machine Learning*, McGraw-Hill Education

5. Kriegel, H.-P. et al. (2020): *K√ºnstliche Intelligenz: Grundlagen intelligenter Systeme*, Springer Vieweg

6. Wikipedia (2025): [K√ºnstliches neuronales Netz](https://de.wikipedia.org/wiki/K√ºnstliches_neuronales_Netz)

7. GeeksforGeeks (2023): [Backpropagation in Neural Network](https://www.geeksforgeeks.org/backpropagation-in-neural-network/)

8. Amazon Web Services (2024): *Was sind Transformer in der k√ºnstlichen Intelligenz? (Abbildung 16)*  
   https://aws.amazon.com/de/what-is/transformers-in-artificial-intelligence/

9. Vaswani, A. et al. (2017): *Attention is All You Need.*  
   https://arxiv.org/abs/1706.03762

10. OpenAI (2023): *Best Practices for Prompt Engineering with GPT.*  
    https://platform.openai.com/docs/guides/gpt-best-practices
11. MathWorks (o.‚ÄØJ.): *Convolutional Neural Networks ‚Äì Aufbau eines CNNs von der Eingabe bis zur Klassifikation * https://de.mathworks.com/discovery/convolutional-neural-network.html
 
